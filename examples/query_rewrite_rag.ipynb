{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49814a62-0201-4d41-a449-c2c6b4ad2ced",
   "metadata": {},
   "source": [
    "# Query Rewriting RAG using Llama Agents\n",
    "\n",
    "In this notebook, we setup two agent services: \n",
    "\n",
    "1. A query rewriting service\n",
    "2. a RAG service \n",
    "\n",
    "Both of these services will be chained together in a simple constrained flow using our Pipeline Orchestrator.\n",
    "\n",
    "After testing our `llama-agents` system, we then detail how to deploy it as a local set of servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e5676-8d15-4372-bc32-8d43dd617b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"llx-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4be8b8-3d1c-4a82-98f5-ec94d97a679e",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First, we load our data and parse it with LlamaParse.\n",
    "\n",
    "If you don't have an API key, you can get one for free at [https://cloud.llamaindex.ai](https://cloud.llamaindex.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa71824",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/10k/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe13aa4-55f7-4854-b2b7-b3ae02d8df75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cac11eca-71fd-4456-93a1-1e35a71a8bcb\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "parser = LlamaParse(result_type=\"text\")\n",
    "docs = parser.load_data(\"data/10k/uber_2021.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968eeda",
   "metadata": {},
   "source": [
    "Next, we index are data and cache to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9feb7-bbd9-46cd-8415-335d37d83827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "if not os.path.exists(\"storage\"):\n",
    "    index = VectorStoreIndex.from_documents(docs)\n",
    "    # save index to disk\n",
    "    index.set_index_id(\"vector_index\")\n",
    "    index.storage_context.persist(\"./storage\")\n",
    "else:\n",
    "    # rebuild storage context\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
    "    # load index\n",
    "    index = load_index_from_storage(storage_context, index_id=\"vector_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed9ff6-7195-4213-b8a1-38dc06c3b25d",
   "metadata": {},
   "source": [
    "## Setup Agents\n",
    "\n",
    "We define a few custom agents: \n",
    "- a retriever agent that will return nodes based on a custom query string\n",
    "- a query rewrite agent that rewrites using a HyDE prompt\n",
    "\n",
    "The agents are defined using the `FnAgentWorker` -- the requirement here is to pass in a function that takes a state dict, performs some operation, and returns the modified state and a boolean indicating if another reasoning loop is needed.\n",
    "\n",
    "The state has two special keys:\n",
    "- `__task__` -- this contains the original input to the agent\n",
    "- `__output__` -- once `is_done=True`, the output should hold the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc8b38-c863-4537-a28e-000d5da52393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define router agent\n",
    "\n",
    "from llama_index.core.agent import FnAgentWorker\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "OPENAI_LLM = OpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# use HyDE to hallucinate answer.\n",
    "HYDE_PROMPT_STR = (\n",
    "    \"Please write a passage to answer the question\\n\"\n",
    "    \"Try to include as many key details as possible.\\n\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    \"{query_str}\\n\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    'Passage:\"\"\"\\n'\n",
    ")\n",
    "HYDE_PROMPT_TMPL = PromptTemplate(HYDE_PROMPT_STR)\n",
    "\n",
    "\n",
    "def run_hdye_fn(state: Dict[str, Any]) -> Tuple[Dict[str, Any], bool]:\n",
    "    \"\"\"Run HyDE.\"\"\"\n",
    "    prompt_tmpl, llm, input_str = (\n",
    "        state[\"prompt_tmpl\"],\n",
    "        state[\"llm\"],\n",
    "        state[\"__task__\"].input,\n",
    "    )\n",
    "    qp = QueryPipeline(chain=[prompt_tmpl, llm])\n",
    "    output = qp.run(query_str=input_str)\n",
    "\n",
    "    state[\"__output__\"] = str(output)\n",
    "\n",
    "    # return state dictionary and also if agent is finished\n",
    "    # for now, we don't loop, and just return True for is_done\n",
    "    is_done = True\n",
    "    return state, is_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad4f2e-f739-4ad7-b5db-6a48adbf4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_agent = FnAgentWorker(\n",
    "    fn=run_hdye_fn, initial_state={\"prompt_tmpl\": HYDE_PROMPT_TMPL, \"llm\": OPENAI_LLM}\n",
    ").as_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c19f5",
   "metadata": {},
   "source": [
    "Next, we define a similar agent to perform RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc290c-1650-480f-8cb7-b81a9f1e1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RAG agent\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "\n",
    "def run_rag_fn(state: Dict[str, Any]) -> Tuple[Dict[str, Any], bool]:\n",
    "    \"\"\"Run RAG.\"\"\"\n",
    "    retriever, llm, input_str = (\n",
    "        state[\"retriever\"],\n",
    "        state[\"llm\"],\n",
    "        state[\"__task__\"].input,\n",
    "    )\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)\n",
    "    response = query_engine.query(input_str)\n",
    "    state[\"__output__\"] = str(response)\n",
    "\n",
    "    is_done = True\n",
    "    return state, is_done\n",
    "\n",
    "\n",
    "rag_agent = FnAgentWorker(\n",
    "    fn=run_rag_fn, initial_state={\"retriever\": index.as_retriever(), \"llm\": OPENAI_LLM}\n",
    ").as_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c488181-3780-429d-b00d-291584b04232",
   "metadata": {},
   "source": [
    "## Setup Agent Services\n",
    "\n",
    "Now, we are ready to build our `llama-agents` system. This includes\n",
    "- A `AgentService` for each agent\n",
    "- A `PipelineOrchestrator` defining the logic for defining the overall flow of tasks through the system\n",
    "- A `SimpleMessageQueue` to facilitate message passing and communcation\n",
    "- A `ControlPlaneServer` to act as the main control-plane for the system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eeaed9-7a9d-4a48-9468-4892ab9aa908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_agents import (\n",
    "    AgentService,\n",
    "    ControlPlaneServer,\n",
    "    SimpleMessageQueue,\n",
    "    PipelineOrchestrator,\n",
    "    ServiceComponent,\n",
    ")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "message_queue = SimpleMessageQueue()\n",
    "\n",
    "## Define Agent Services\n",
    "query_rewrite_server = AgentService(\n",
    "    agent=hyde_agent,\n",
    "    message_queue=message_queue,\n",
    "    description=\"Used to rewrite queries\",\n",
    "    service_name=\"query_rewrite_agent\",\n",
    ")\n",
    "query_rewrite_server_c = ServiceComponent.from_service_definition(query_rewrite_server)\n",
    "\n",
    "rag_agent_server = AgentService(\n",
    "    agent=rag_agent, message_queue=message_queue, description=\"rag_agent\"\n",
    ")\n",
    "rag_agent_server_c = ServiceComponent.from_service_definition(rag_agent_server)\n",
    "\n",
    "# create our multi-agent framework components and orchestrator\n",
    "pipeline = QueryPipeline(chain=[query_rewrite_server_c, rag_agent_server_c])\n",
    "pipeline_orchestrator = PipelineOrchestrator(pipeline)\n",
    "\n",
    "control_plane = ControlPlaneServer(\n",
    "    message_queue=message_queue,\n",
    "    orchestrator=pipeline_orchestrator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19df0c2-7abe-4563-a4d8-3a47c13b65d0",
   "metadata": {},
   "source": [
    "## Launch agent \n",
    "\n",
    "Using a `LocalLauncher`, we can simulate single passes of tasks through our `llama-agents` system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41c86a-fd43-4f82-85ea-90f1208e810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_agents.launchers import LocalLauncher\n",
    "\n",
    "## Define Launcher\n",
    "launcher = LocalLauncher(\n",
    "    [query_rewrite_server, rag_agent_server],\n",
    "    control_plane,\n",
    "    message_queue,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf856b-762c-4608-ac02-c1d5fc75bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What are the risk factors for Uber?\"\n",
    "result = launcher.launch_single(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ccb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uber, as a leading ride-sharing company, faces a multitude of risk factors that could impact its operations, financial performance, and overall market position. These risks can be broadly categorized into regulatory, operational, financial, competitive, and reputational risks.\n",
      "\n",
      "**Regulatory Risks:** Uber operates in a highly regulated industry, and changes in laws and regulations can significantly affect its business model. Different countries and cities have varying regulations regarding ride-sharing services, including licensing requirements, fare controls, and driver background checks. Compliance with these regulations can be costly and complex. Additionally, there is always the risk of new regulations being introduced that could limit Uber's ability to operate or increase its operational costs.\n",
      "\n",
      "**Operational Risks:** Uber relies heavily on its technology platform to connect drivers with passengers. Any technical failures, cybersecurity breaches, or data privacy issues could disrupt its services and erode customer trust. Furthermore, Uber's business model depends on a large pool of drivers. Changes in labor laws, such as reclassification of drivers from independent contractors to employees, could increase labor costs and reduce flexibility.\n",
      "\n",
      "**Financial Risks:** Uber has historically operated at a loss, and there is no guarantee that it will achieve profitability. The company invests heavily in technology, marketing, and expansion into new markets, which requires substantial capital. Fluctuations in fuel prices, insurance costs, and vehicle maintenance expenses also pose financial risks. Additionally, Uber's financial performance is sensitive to economic conditions; during economic downturns, demand for ride-sharing services may decline.\n",
      "\n",
      "**Competitive Risks:** The ride-sharing market is highly competitive, with numerous players such as Lyft, Didi, and Ola vying for market share. Competition can lead to price wars, reduced margins, and increased customer acquisition costs. Uber also faces competition from traditional taxi services and emerging transportation technologies, such as autonomous vehicles and electric scooters.\n",
      "\n",
      "**Reputational Risks:** Uber's reputation is crucial to its success. Negative publicity related to safety incidents, driver misconduct, or corporate governance issues can damage its brand and lead to loss of customers. The company has faced criticism and legal challenges over its handling of sexual harassment claims, data breaches, and aggressive business practices. Maintaining a positive public image is essential for customer retention and regulatory goodwill.\n",
      "\n",
      "In summary, Uber's risk factors are multifaceted and interconnected. Regulatory changes, operational challenges, financial uncertainties, intense competition, and reputational issues all pose significant threats to the company's stability and growth. Addressing these risks requires strategic planning, robust risk management practices, and continuous adaptation to the evolving market landscape.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3688f-cad4-450e-81fa-037dd1190260",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What was Uber's revenue growth in 2021?\"\n",
    "result = launcher.launch_single(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c685b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2021, Uber Technologies Inc. experienced significant revenue growth, reflecting a strong recovery from the pandemic-induced downturn of the previous year. The company's total revenue for the year amounted to $17.5 billion, marking a substantial increase from the $11.1 billion reported in 2020. This impressive growth was driven by a resurgence in demand for ride-hailing services as vaccination rates increased and economies reopened, coupled with the continued expansion of Uber Eats, the company's food delivery segment. Uber's mobility segment, which includes ride-hailing, saw a notable rebound, while the delivery segment maintained its momentum, contributing to the overall revenue surge. Additionally, Uber Freight, the company's logistics arm, also played a role in bolstering revenue. The combination of these factors resulted in a year-over-year revenue growth of approximately 57%, underscoring Uber's resilience and adaptability in a challenging market environment.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d20d8",
   "metadata": {},
   "source": [
    "## Launch as a Service\n",
    "\n",
    "With our `llama-agents` system tested and working, we can launch it as a service and interact with it using the `llama-agents monitor`.\n",
    "\n",
    "**NOTE:** This code is best launched from a separate python script, outside of a notebook.\n",
    "\n",
    "Also note that for launching as a server, we explicitly add a consumer for \"human\" messages (this is where final results are published to by default).\n",
    "\n",
    "Python Code in `app.py`:\n",
    "```python\n",
    "\n",
    "######  <setup custom FnAgentWorkers, pipelines>  ######\n",
    "\n",
    "from llama_agents import (\n",
    "    AgentService,\n",
    "    CallableMessageConsumer,\n",
    "    ControlPlaneServer,\n",
    "    SimpleMessageQueue,\n",
    "    PipelineOrchestrator,\n",
    "    ServiceComponent,\n",
    ")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "message_queue = SimpleMessageQueue(\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8010,\n",
    ")\n",
    "\n",
    "## Define Agent Services\n",
    "query_rewrite_server = AgentService(\n",
    "    agent=hyde_agent,\n",
    "    message_queue=message_queue,\n",
    "    description=\"Used to rewrite queries\",\n",
    "    service_name=\"query_rewrite_agent\",\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8011,\n",
    ")\n",
    "query_rewrite_server_c = ServiceComponent.from_service_definition(query_rewrite_server)\n",
    "\n",
    "rag_agent_server = AgentService(\n",
    "    agent=rag_agent,\n",
    "    message_queue=message_queue,\n",
    "    description=\"rag_agent\",\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8012,\n",
    ")\n",
    "rag_agent_server_c = ServiceComponent.from_service_definition(rag_agent_server)\n",
    "\n",
    "# create our multi-agent framework components\n",
    "pipeline = QueryPipeline(chain=[query_rewrite_server_c, rag_agent_server_c])\n",
    "pipeline_orchestrator = PipelineOrchestrator(pipeline)\n",
    "control_plane = ControlPlaneServer(\n",
    "    message_queue=message_queue,\n",
    "    orchestrator=pipeline_orchestrator,\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8013,\n",
    ")\n",
    "\n",
    "# Additional human consumer\n",
    "def handle_result(message: QueueMessage) -> None:\n",
    "    print(f\"Got result:\", message.data)\n",
    "\n",
    "human_consumer = CallableMessageConsumer(\n",
    "    handler=handle_result, message_type=\"human\"\n",
    ")\n",
    "\n",
    "from llama_agents.launchers import ServerLauncher\n",
    "\n",
    "## Define Launcher\n",
    "launcher = ServerLauncher(\n",
    "    [query_rewrite_server, rag_agent_server],\n",
    "    control_plane,\n",
    "    message_queue,\n",
    "    additional_consumers=[human_consumer],\n",
    ")\n",
    "\n",
    "launcher.launch_servers()\n",
    "```\n",
    "\n",
    "Launch the app:\n",
    "```bash\n",
    "python ./app.py\n",
    "```\n",
    "\n",
    "In another terminal, launch the Monitor:\n",
    "```bash\n",
    "llama-agents monitor --control-plane-url http://127.0.0.1:8013\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bec368",
   "metadata": {},
   "source": [
    "Now, we can see our monitor, send in new tasks/queries, and observe the states of services."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentfile-MFMS50kK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
