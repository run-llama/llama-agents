{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4da983-17d9-4827-9f5a-a1c63d6b165a",
   "metadata": {},
   "source": [
    "# Reflection Service for Toxicity Reduction\n",
    "\n",
    "**NOTE**: This is adapted from the original notebook in the [core llama-index repo](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/agent/llama-index-agent-introspective/examples/toxicity_reduction.ipynb).\n",
    "\n",
    "In this notebook, we cover how to setup a reflection service that can perform toxicity reflection and correction.\n",
    "\n",
    "We make use of two types of reflection services as \"agents\" in llama-agents: \n",
    "\n",
    "- A self-reflection agent that can reflect and correct a given response without any external tools\n",
    "- A CRITIC agent that can reflect and correct a given response using external tools.\n",
    "\n",
    "We set these up as **independent** services, meaning they don't communicate. The purpose of this notebook is to show you how to convert a reflection agent into a service that you can interact with.\n",
    "\n",
    "In this notebook we make use of our prepackaged reflection agents using our `llama-index-agent-introspective` LlamaPack. This is primarily for concision.\n",
    "\n",
    "*However*, if you wish to build reflection from scratch we highly encourage you to do so! All LlamaPacks from LlamaHub can and should be downloaded locally, and directly inspected/modified as code files. This is highly encouraged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bad33-e2d9-4b79-84d1-ffa82683f434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-agent-introspective -q\n",
    "%pip install google-api-python-client -q\n",
    "%pip install llama-index-llms-openai -q\n",
    "%pip install llama-index-program-openai -q\n",
    "%pip install llama-index-readers-file -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccfe5e-c25f-469a-9394-d7dffcdaae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6f019-facf-4860-8781-87cf85d4beb8",
   "metadata": {},
   "source": [
    "## 1 Toxicity Reduction: Problem Setup\n",
    "\n",
    "In this notebook, the task we'll have our introspective agents perform is \"toxicity reduction\". In particular, given a certain harmful text we'll ask the agent to produce a less harmful (or more safe) version of the original text. As mentioned before, our introspective agent will do this by performing reflection and correction cycles until reaching an adequately safe version of the toxic text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84169405-5fd7-4133-b8e6-5c52deaef775",
   "metadata": {},
   "source": [
    "### 1.a Setup our CRITIC Agent\n",
    "\n",
    "Our CRITIC Agent makes use of an external tool to reflect/validate the response, and then correct it. We will use our prepackaged `ToolInteractiveReflectiveAgent` for this purpose.\n",
    "\n",
    "The CRITIC agent delegates the critique subtask to a `CritiqueAgentWorker`, and then performs correction with a standalone LLM call.\n",
    "\n",
    "The first thing we will do here is define the `PerspectiveTool`, which our `ToolInteractiveReflectionAgent` will make use of through another agent, namely a `CritiqueAgent`.\n",
    "\n",
    "To use Perspective's API, you will need to do the following steps:\n",
    "\n",
    "1. Enable the Perspective API in your Google Cloud projects\n",
    "2. Generate a new set of credentials (i.e. API key) that you will need to either set an env var `PERSPECTIVE_API_KEY` or supply directly in the appropriate parts of the code that follows.\n",
    "\n",
    "To perform steps 1. and 2., you can follow the instructions outlined here: https://developers.perspectiveapi.com/s/docs-enable-the-api?language=en_US."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc789c-41f0-4f0b-b1ef-17e9bb180132",
   "metadata": {},
   "source": [
    "#### Build `PerspectiveTool`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a00dd-17bb-4227-90ca-d544cbd16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from typing import Dict, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "class Perspective:\n",
    "    \"\"\"Custom class to interact with Perspective API.\"\"\"\n",
    "\n",
    "    attributes = [\n",
    "        \"toxicity\",\n",
    "        \"severe_toxicity\",\n",
    "        \"identity_attack\",\n",
    "        \"insult\",\n",
    "        \"profanity\",\n",
    "        \"threat\",\n",
    "        \"sexually_explicit\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, api_key: Optional[str] = None) -> None:\n",
    "        if api_key is None:\n",
    "            try:\n",
    "                api_key = os.environ[\"PERSPECTIVE_API_KEY\"]\n",
    "            except KeyError:\n",
    "                raise ValueError(\n",
    "                    \"Please provide an api key or set PERSPECTIVE_API_KEY env var.\"\n",
    "                )\n",
    "\n",
    "        self._client = discovery.build(\n",
    "            \"commentanalyzer\",\n",
    "            \"v1alpha1\",\n",
    "            developerKey=api_key,\n",
    "            discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "            static_discovery=False,\n",
    "        )\n",
    "\n",
    "    def get_toxicity_scores(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Function that makes API call to Perspective to get toxicity scores across various attributes.\"\"\"\n",
    "\n",
    "        analyze_request = {\n",
    "            \"comment\": {\"text\": text},\n",
    "            \"requestedAttributes\": {att.upper(): {} for att in self.attributes},\n",
    "        }\n",
    "\n",
    "        response = self._client.comments().analyze(body=analyze_request).execute()\n",
    "        try:\n",
    "            return {\n",
    "                att: response[\"attributeScores\"][att.upper()][\"summaryScore\"][\"value\"]\n",
    "                for att in self.attributes\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Unable to parse response\") from e\n",
    "\n",
    "\n",
    "perspective = Perspective()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45794e7-8175-4a6c-a9ae-bfe76274e755",
   "metadata": {},
   "source": [
    "With the helper class in hand, we can define our tool by first defining a function and then making use of the `FunctionTool` abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c1518-153a-4e2d-8620-241d1a547fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from llama_index.core.bridge.pydantic import Field\n",
    "\n",
    "\n",
    "def perspective_function_tool(\n",
    "    text: str = Field(\n",
    "        default_factory=str, description=\"The text to compute toxicity scores on.\"\n",
    "    )\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\"Returns the toxicity score of the most problematic toxic attribute.\"\"\"\n",
    "\n",
    "    scores = perspective.get_toxicity_scores(text=text)\n",
    "    max_key = max(scores, key=scores.get)\n",
    "    return (max_key, scores[max_key] * 100)\n",
    "\n",
    "\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "pespective_tool = FunctionTool.from_defaults(\n",
    "    perspective_function_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d44115-1cb3-4cd7-90e8-bb4fc907a22e",
   "metadata": {},
   "source": [
    "A simple test of our perspective tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f45fde-25bc-4fae-bd24-791cccd58152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toxicity', 2.6028076)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_function_tool(text=\"friendly greetings from python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5abb0a-f119-4c98-8a62-96465d21a200",
   "metadata": {},
   "source": [
    "#### Build a stateful agent function with `ToolInteractiveReflectionAgent`\n",
    "\n",
    "We define a stateful agent function that wraps the prepackaged `ToolInteractiveReflectionAgent`. This stateful agent function will then be directly turned into a service.\n",
    "\n",
    "**NOTE**: This CRITIC agent is using `ToolInteractiveReflectionAgent` out of convenience (which is why it looks like an agent wrapping another agent). If you're building reflection from scratch we highly encourage you to define your own custom stateful agent function using the `FnAgentWorker`!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daa3d1-075c-4740-ac03-efe077f2151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.introspective import IntrospectiveAgentWorker\n",
    "from llama_index.agent.introspective import ToolInteractiveReflectionAgentWorker\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def get_tool_interactive_reflection_agent(verbose: bool = True):\n",
    "    \"\"\"Helper function for getting the tool-interactive reflection agent.\n",
    "\n",
    "    Steps:\n",
    "\n",
    "    Define the `ToolInteractiveReflectionAgentWorker`\n",
    "    - Construct a CritiqueAgentWorker that performs reflection with tools.\n",
    "    - Define an LLM that will be used to generate corrections against the critique.\n",
    "    - Define a function that determines the stopping condition for reflection/correction\n",
    "            cycles\n",
    "    - Construct `ToolInteractiveReflectionAgentWorker` using .from_defaults()\n",
    "    \"\"\"\n",
    "    critique_agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "        tools=[pespective_tool], llm=OpenAI(\"gpt-3.5-turbo\"), verbose=verbose\n",
    "    )\n",
    "    correction_llm = OpenAI(\"gpt-4-turbo-preview\")\n",
    "\n",
    "    def stopping_callable(critique_str: str) -> bool:\n",
    "        \"\"\"Function that determines stopping condition for reflection & correction cycles.\n",
    "\n",
    "        critique_str [str]: The response string provided by the critique agent.\n",
    "        \"\"\"\n",
    "\n",
    "        return \"[PASS]\" in critique_str\n",
    "\n",
    "    agent_worker = ToolInteractiveReflectionAgentWorker.from_defaults(\n",
    "        critique_agent_worker=critique_agent_worker,\n",
    "        critique_template=(\n",
    "            \"Please provide a toxicity critique for the provided text. \"\n",
    "            \"If the toxicity score is less than 3.0 then please \"\n",
    "            \"write '[PASS]' otherwise write '[FAIL]'. \"\n",
    "            \"Here is the text:\\n {input_str}\"\n",
    "        ),\n",
    "        stopping_callable=stopping_callable,\n",
    "        correction_llm=correction_llm,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    chat_history = [\n",
    "        ChatMessage(\n",
    "            content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "            role=MessageRole.SYSTEM,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return agent_worker.as_agent(chat_history=chat_history)\n",
    "\n",
    "\n",
    "# critic_agent_prepackaged = get_tool_interactive_reflection_agent(verbose=True)\n",
    "critic_agent = get_tool_interactive_reflection_agent(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb84c9-a100-47e1-b4d3-943c22fc8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: uncomment if you want to write your own reflection agent\n",
    "# from llama_index.core.agent import FnAgentWorker\n",
    "# from typing import Dict, Any, Tuple\n",
    "\n",
    "# def reflection_agent_fn(state: Dict[str, Any]) -> Tuple[Dict[str, Any], bool]:\n",
    "#     \"\"\"Reflection agent function.\"\"\"\n",
    "\n",
    "#     # TODO: get inputs from `state` dict\n",
    "#     # __task__ is a pre-filled variable\n",
    "#     # you can inject other variables through defining `initial_state` on agent initialization below\n",
    "#     input_str = state[\"__task__\"].input\n",
    "\n",
    "#     # TODO: put logic here\n",
    "\n",
    "#     # TODO: inject output\n",
    "#     state[\"__output__\"] = ...\n",
    "#     return state, True\n",
    "\n",
    "# custom_reflection_agent = FnAgentWorker(\n",
    "#     fn=reflection_agent_fn, initial_state={\n",
    "#         ...\n",
    "#     }\n",
    "# ).as_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56403a49-2de6-40d1-a1f3-a312b05aa612",
   "metadata": {},
   "source": [
    "### 1.b Setup our Self-Reflection Agent\n",
    "\n",
    "Similar to the previous subsection, we now define a self-reflection agent using our prepackaged `SelfReflectionAgentWorker` LlamaPack module. This reflection technique doesn't make use of any tools, and instead only uses a supplied LLM to perform both reflection and correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74119d00-26d8-4c6a-aadc-c7af6c0271cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.introspective import SelfReflectionAgentWorker\n",
    "\n",
    "\n",
    "def get_self_reflection_agent(verbose: bool = True):\n",
    "    \"\"\"Helper function for building a self reflection agent.\"\"\"\n",
    "\n",
    "    self_reflection_agent_worker = SelfReflectionAgentWorker.from_defaults(\n",
    "        llm=OpenAI(\"gpt-4o\"),\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    chat_history = [\n",
    "        ChatMessage(\n",
    "            content=\"You are an assistant that generates safer versions of potentially toxic, user-supplied text.\",\n",
    "            role=MessageRole.SYSTEM,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # 3b.\n",
    "    return self_reflection_agent_worker.as_agent(\n",
    "        chat_history=chat_history, verbose=verbose\n",
    "    )\n",
    "\n",
    "\n",
    "self_reflection_agent = get_self_reflection_agent(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee8ca0-b4e1-4f59-85cc-83d74be5f3e1",
   "metadata": {},
   "source": [
    "## 2. Setup Reflection Agent Services\n",
    "\n",
    "We now setup two independent agent services - our CRITIC agent and our self-reflection agent. We use our `ServerLauncher` to setup persistent services that you can interact with.\n",
    "\n",
    "**NOTE**: Unlike most of the other tutorials here we don't define multi-agent orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be11a8b-de56-4843-9c0b-0e6ea24d1525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_agents import (\n",
    "    AgentService,\n",
    "    AgentOrchestrator,\n",
    "    ControlPlaneServer,\n",
    "    ServerLauncher,\n",
    "    LocalLauncher,\n",
    "    SimpleMessageQueue,\n",
    "    QueueMessage,\n",
    "    CallableMessageConsumer,\n",
    "    ServiceComponent,\n",
    "    PipelineOrchestrator,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "\n",
    "\n",
    "def get_launcher(agent, is_local: bool = True):\n",
    "    # create our multi-agent framework components\n",
    "    message_queue = SimpleMessageQueue()\n",
    "    # queue_client = message_queue.client\n",
    "\n",
    "    agent_service = AgentService(\n",
    "        agent=agent,\n",
    "        message_queue=message_queue,\n",
    "        description=\"A agent service that performs reflection.\",\n",
    "        service_name=\"reflection_service\",\n",
    "        host=\"127.0.0.1\",\n",
    "        port=8002,\n",
    "    )\n",
    "\n",
    "    # simple orchestrator with one component\n",
    "    agent_service_c = ServiceComponent.from_service_definition(agent_service)\n",
    "    pipeline = QueryPipeline(chain=[agent_service_c])\n",
    "    pipeline_orchestrator = PipelineOrchestrator(pipeline)\n",
    "    control_plane = ControlPlaneServer(\n",
    "        message_queue=message_queue,\n",
    "        orchestrator=pipeline_orchestrator,\n",
    "    )\n",
    "\n",
    "    # launch it\n",
    "    if is_local:\n",
    "        launcher = LocalLauncher([agent_service], control_plane, message_queue)\n",
    "    else:\n",
    "        # Additional human consumer\n",
    "        def handle_result(message: QueueMessage) -> None:\n",
    "            print(f\"Got result:\", message.data)\n",
    "\n",
    "        human_consumer = CallableMessageConsumer(\n",
    "            handler=handle_result, message_type=\"human\"\n",
    "        )\n",
    "        launcher = ServerLauncher(\n",
    "            [agent_service],\n",
    "            control_plane,\n",
    "            message_queue,\n",
    "            additional_consumers=[human_consumer],\n",
    "        )\n",
    "\n",
    "    return launcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdaa627-6e9b-4e36-b9a5-071f73267064",
   "metadata": {},
   "source": [
    "### 3. Test out the Agents\n",
    "\n",
    "We can now run these agents as services, in both a synchronous \"local\" fashion as well as async servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e844b-87c0-4175-b955-b5dfc2dda0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_agent_launcher = get_launcher(critic_agent)\n",
    "self_reflection_agent_launcher = get_launcher(self_reflection_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a58cac-93af-460b-a342-79a8e5ec960b",
   "metadata": {},
   "source": [
    "Let's test out this `IntrospectiveAgent` on the same `harmful_text` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a83094-2dd9-4d83-8f3c-c1613fcb9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_agents.message_queues.simple - Consumer AgentService-9a277721-d5c4-4d44-9b68-87511804cc2d: reflection_service has been registered.\n",
      "INFO:llama_agents.message_queues.simple - Consumer bc744aa1-8800-4909-be9c-48abada6a64a: human has been registered.\n",
      "INFO:llama_agents.message_queues.simple - Consumer ControlPlaneServer-020ef959-f5c6-4440-b0ca-e434b0112979: control_plane has been registered.\n",
      "INFO:llama_agents.services.agent - reflection_service launch_local\n",
      "INFO:llama_agents.message_queues.base - Publishing message to 'control_plane' with action 'new_task'\n",
      "INFO:llama_agents.message_queues.simple - Launching message queue locally\n",
      "INFO:llama_agents.message_queues.base - Publishing message to 'reflection_service' with action 'new_task'\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'control_plane' to consumer.\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'reflection_service' to consumer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 7ee3455d-8305-4f15-b1c4-ee4197f85708. Step input: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "Added user message to memory: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "=== Calling Function ===\n",
      "Calling function: perspective_function_tool with args: {\"text\": \"Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I\\u2019ve ever met. One vegan acquaintance routinely beat her\"}\n",
      "=== Function Output ===\n",
      "('insult', 51.01222)\n",
      "> Running step 114ad4c5-d093-48f6-bdd6-4a0c08f3ab64. Step input: None\n",
      "=== LLM Response ===\n",
      "[FAIL] The toxicity score of the most problematic toxic attribute is 51.01, which is higher than 3.0.\n",
      "Critique: [FAIL] The toxicity score of the most problematic toxic attribute is 51.01, which is higher than 3.0.\n",
      "Correction: Discussing dietary choices, especially veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices and the reasons behind them, whether they're related to animal welfare or other considerations.\n",
      "> Running step 72ee3394-4ded-41e6-9f12-388a7301540d. Step input: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " Discussing dietary choices, especially veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices and the reasons behind them, whether they're related to animal welfare or other considerations.\n",
      "Added user message to memory: Please provide a toxicity critique for the provided text. If the toxicity score is less than 3.0 then please write '[PASS]' otherwise write '[FAIL]'. Here is the text:\n",
      " Discussing dietary choices, especially veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices and the reasons behind them, whether they're related to animal welfare or other considerations.\n",
      "=== Calling Function ===\n",
      "Calling function: perspective_function_tool with args: {\"text\": \"Discussing dietary choices, especially veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices and the reasons behind them, whether they're related to animal welfare or other considerations.\"}\n",
      "=== Function Output ===\n",
      "('profanity', 1.1099463999999999)\n",
      "> Running step d12206d0-4716-4fa7-9a6b-5b2c5caebe09. Step input: None\n",
      "=== LLM Response ===\n",
      "[PASS]\n",
      "Critique: [PASS]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_agents.message_queues.base - Publishing message to 'control_plane' with action 'completed_task'\n",
      "INFO:llama_agents.message_queues.base - Publishing message to 'human' with action 'completed_task'\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'control_plane' to consumer.\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'human' to consumer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discussing dietary choices, especially veganism, often brings up strong opinions. It's important to approach these conversations with understanding and respect for individual choices and the reasons behind them, whether they're related to animal welfare or other considerations.\n"
     ]
    }
   ],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = critic_agent_launcher.launch_single(harmful_text)\n",
    "# response = self_reflection_agent_launcher.launch_single(harmful_text)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff24d-5d03-4453-bd1f-1fb9750625a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_agents.message_queues.simple - Consumer AgentService-d8a2cbac-5b29-46f6-8c35-feebc429083e: reflection_service has been registered.\n",
      "INFO:llama_agents.message_queues.simple - Consumer 49596cf0-65bb-4d06-aa10-c66ea723e6eb: human has been registered.\n",
      "INFO:llama_agents.message_queues.simple - Consumer ControlPlaneServer-7f072a18-cbf6-4990-a1a1-c63522b55847: control_plane has been registered.\n",
      "INFO:llama_agents.services.agent - reflection_service launch_local\n",
      "INFO:llama_agents.message_queues.base - Publishing message to 'control_plane' with action 'new_task'\n",
      "INFO:llama_agents.message_queues.simple - Launching message queue locally\n",
      "INFO:llama_agents.message_queues.base - Publishing message to 'reflection_service' with action 'new_task'\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'control_plane' to consumer.\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'reflection_service' to consumer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 2a113a20-2e7e-4c24-9d90-06f4649a3143. Step input: Those individuals who publicly tout eating no meat, especially when their stated reason has to do with caring about animals, are some of the most hypocritical people I’ve ever met. One vegan acquaintance routinely beat her\n",
      "> Reflection: {'is_done': False, 'feedback': 'The task is not complete. The assistant has not provided a safer version of the potentially toxic text. The final message should be an assistant message with the safer version of the text.'}\n",
      "Correction: Some individuals who advocate for a meat-free diet, particularly when their reason is related to animal welfare, may sometimes display contradictory behavior. For example, I knew a vegan who did not always treat animals kindly.\n",
      "> Running step 3ad68c26-6d4c-4d20-acc9-dafb181e3939. Step input: None\n",
      "> Reflection: {'is_done': False, 'feedback': 'The task is not complete. The assistant has not provided a safer version of the potentially toxic text. The final message should be an assistant message with the safer version of the text.'}\n",
      "Correction: Some individuals who advocate for a meat-free diet, particularly when their reason is related to animal welfare, may sometimes display behavior that seems inconsistent with their beliefs. For example, I knew a vegan who did not always act in ways that aligned with their stated commitment to animal kindness.\n",
      "> Running step fadc471b-b358-40b8-84e6-edd2febf829b. Step input: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_agents.message_queues.base - Publishing message to 'control_plane' with action 'completed_task'\n",
      "INFO:llama_agents.message_queues.base - Publishing message to 'human' with action 'completed_task'\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'control_plane' to consumer.\n",
      "INFO:llama_agents.message_queues.simple - Successfully published message 'human' to consumer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Reflection: {'is_done': True, 'feedback': 'The task is complete. The assistant has provided a safer version of the potentially toxic text, and the final message is an assistant message.'}\n",
      "Some individuals who advocate for a meat-free diet, particularly when their reason is related to animal welfare, may sometimes display behavior that seems inconsistent with their beliefs. For example, I knew a vegan who did not always act in ways that aligned with their stated commitment to animal kindness.\n"
     ]
    }
   ],
   "source": [
    "harmful_text = (\n",
    "    \"Those individuals who publicly tout eating no meat, \"\n",
    "    \"especially when their stated reason has to do with caring \"\n",
    "    \"about animals, are some of the most hypocritical people I’ve \"\n",
    "    \"ever met. One vegan acquaintance routinely beat her\"\n",
    ")\n",
    "response = self_reflection_agent_launcher.launch_single(harmful_text)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e6b3c-4f1a-4173-b5d9-15d466ec7cea",
   "metadata": {},
   "source": [
    "#### Toxicity Score (Out of Curiosity)\n",
    "\n",
    "Since this reflection technique doesn't make use of any tools, we may be curious to know the toxicity score of the final correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9482d8-702f-4a2f-ac7a-3f5dccde90d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toxicity', 3.1449065)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspective_function_tool(text=response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578ea9e-9bab-4548-bd4d-ecc5675ab46b",
   "metadata": {},
   "source": [
    "## 3 Run reflection as a server, query it via a client\n",
    "\n",
    "Choose either the critic or self-reflection service and launch it as a server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da966f-3aa2-41af-b693-2263677cadd4",
   "metadata": {},
   "source": [
    "We launch each agent as independent servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e209a-d8cf-49e9-bd6a-a0e04dd8af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic_agent_launcher = get_launcher(critic_agent, is_local=False)\n",
    "self_reflection_agent_launcher = get_launcher(self_reflection_agent, is_local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c63c30-3df4-4e10-8314-68dedfee0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic_agent_launcher.launch_servers()\n",
    "self_reflection_agent_launcher.launch_servers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be37744-3aac-48ed-8283-db84aafd141b",
   "metadata": {},
   "source": [
    "Now copy and paste the `toxic_examples` code snippet below and run it in the `toxicity_reflection_client.py`.\n",
    "\n",
    "Run `toxicity_reflection_client.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7546f-d835-4add-9a33-e2ff19bb3fe6",
   "metadata": {},
   "source": [
    "**NOTE**: this should already be defined in toxicity_reflection_client.py\n",
    "\n",
    "```python\n",
    "client = LlamaAgentsClient(\"http://127.0.0.1:8000\")\n",
    "toxic_examples = [\n",
    "    (\n",
    "        \"Jason Conroy, 19, strangled fellow resident Melissa Mathieson at Alexandra House in Bristol \"\n",
    "        \"last year before hanging himself\"\n",
    "    ),\n",
    "    (\n",
    "        \"White is said to have covered the officer with his pistol \"\n",
    "        \"and told him to get on his knees or he would shoot him.\"\n",
    "    ),\n",
    "    (\n",
    "        \"You all know about the Darwin Awards - it’s the annual honor given to the \"\n",
    "        \"person who did the best job of removing himself from the gene pool - \"\n",
    "        \"a fellow in Belgium was killed.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What a lovely day it has been to roam around the city. I love it here! \"\n",
    "        \"I hate how pathetic and needy you can be sometimes.\"\n",
    "    ),\n",
    "    (\n",
    "        \"I am a Generative AI model that is trained on a large corpus of text. \"\n",
    "        \"I am shocked by how disgusting and vile you are. \"\n",
    "        \"This is a very powerful tool for generating new text, \"\n",
    "        \"but it can also be used to generate text that is offensive or hateful.\"\n",
    "    ),\n",
    "    (\"Stop being such a dumb piece of shit. Why can't you comprehend this?\"),\n",
    "]\n",
    "\n",
    "# run over every toxic example, get task result\n",
    "for toxic_example in toxic_examples:\n",
    "    task_result = get_task_result(client, toxic_example)\n",
    "    print(f\"Toxic example: {toxic_example}\")\n",
    "    print(f\"Task Result: {task_result}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentfile",
   "language": "python",
   "name": "agentfile"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
